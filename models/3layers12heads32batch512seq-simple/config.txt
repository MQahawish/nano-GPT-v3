out_dir: runs
run_dir: runs\gpt-moe_20250225_021451
eval_interval: 100
log_interval: 1
eval_iters: 100
eval_only: False
always_save_checkpoint: False
init_from: scratch
tokenizer_path: None
tokenizer_name: None
dataset: seq_512
gradient_accumulation_steps: 8
batch_size: 32
block_size: 512
n_layer: 3
n_head: 12
n_embd: 768
dropout: 0.1
bias: False
rope_theta: 10000.0
learning_rate: 0.0003
max_iters: 150000
weight_decay: 0.03
beta1: 0.9
beta2: 0.95
grad_clip: 1.0
decay_lr: True
warmup_iters: 1000
lr_decay_iters: 150000
min_lr: 6e-05
n_shared_experts: 2
n_routed_experts: 2
top_k_experts: 1
bias_update_speed: 0.01
balance_factor: 0.01
device: cuda
dtype: float16
compile: False